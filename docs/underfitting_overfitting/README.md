### Underfitting and Overfitting

* A model that generalizes well is a model 
  that is neither underfit nor overfit.

<img src="./over_and_under_fitting.png" alt="over_and_under_fitting">

* Generalization and overfitting

```
	â€¢ Generalization: A classifier or a regression 
	  algorithm learns to correctly predict output 
	  from given inputs not only in previously seen 
	  samples but also in previously unseen samples.

	â€¢ Overfitting: A classifier or a regression 
	  algorithm learns to correctly predict output 
	  from given inputs in previously seen samples 
	  but fails to do so in previously unseen samples.

	â€¢ Overfitting => Poor generalization.
````

* Underfitting

````
    Underfitting occurs when a model canâ€™t accurately 
    capture the dependencies among data, usually as a 
    consequence of its own simplicity. It often yields 
    a low ğ‘…Â² with known data and bad generalization 
    capabilities when applied with new data.
````

* Overfitting

````
    Overfitting  happens  when a  model learns both 
    dependencies  among  data  and random fluctuations. 
    In other words, a model learns the existing data 
    too well. Complex models, which have many features 
    or terms, are  often  prone  to overfitting. When 
    applied to known data, such models usually yield 
    high ğ‘…Â². However, they  often  donâ€™t  generalize  
    well  and  have significantly lower ğ‘…Â² when used 
    with new data.
````

* [What Are Overfitting and Underfitting in Machine Learning?](https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690)

* [Overfitting and Underfitting in Machine Learning - video 17 minutes](https://www.youtube.com/watch?v=j9_yzC-x-js)

